{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation\n",
    "\n",
    "In diesem Notebook m√∂chten wir uns mit der K√∂nigsdisziplin des Natural Language Processings besch√§ftigen, der maschinellen √úbersetzung.\n",
    "Vermutlich gibt es keine NLP-Anwendung, die einerseits vielen bekannt ist, anderseits durch Deep Learning und neuronalen Netzen einen solchen Aufschwung bekommen hat.\n",
    "Vor dem Siegeszug der neuronalen Netzen, wurde maschinelle √úbersetzung deshalb als schwierig angesehen, weil sie alle Teilaspekte von Sprache beinhaltet. Neben grammatikalischer Korrektheit, sollen maschinell √ºbersetzte Texte den Sinn des Originaltextes wiedergeben und dar√ºberhinaus auch den Subtext, wie Ironie, Witz, erfassen.\n",
    "Ob letzteres einfach gelingt, sei hier mal dahingestellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten\n",
    "Im Vergleich zu den bisherigen Notebooks sind die Daten f√ºr machine translation etwas dr√∂ge. Daher m√∂chten wir uns hier nicht allzu lange aufhalten. Speichert zun√§chst folgende Datei ab und entpackt sie: http://www.manythings.org/anki/fra-eng.zip\n",
    "\n",
    "Danach wollen wir die Daten einlesen. Das Format ist einfach, pro Zeile steht ein Satzpaar getrennt von einem Tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fra.txt', 'r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [tuple(l.split(\"\\t\")) for l in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_cleaned = [(e, f.strip()) for e, f in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit unser Modell wei√ü wo Anfang und Ende der franz√∂sischen S√§tze sind, m√ºssen wir noch ein spezielles Start- (üè≥Ô∏è) und Endsymbol (üè¥) einf√ºgen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_cleaned_with_marker = [(e, \"üè≥Ô∏è\" + f + \"üè¥\") for e, f in pairs_cleaned]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speichert euch nun alle Character, die in den englischen S√§tzen und in den franz√∂sischen S√§tzen in jeweils einem Set ab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Go.', 'üè≥Ô∏èVa !üè¥')\n"
     ]
    }
   ],
   "source": [
    "print(pairs_cleaned_with_marker[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'q', 'U', '0', '3', 'e', '√∂', 'I', 'p', 'n', '‚Äô', 'o', 'H', 'a', 'k', '‚ÇÇ', 'P', 'E', '?', 's', '1', 'G', '\"', '!', ' ', '$', ',', 'S', '+', 'j', 'Y', '\\xa0', '.', '√©', 'r', '‚Äî', 'M', '2', '4', 'A', 'O', ':', '\\xad', 'b', '/', 'u', 'X', 't', '‚Äò', 'm', 'Q', \"'\", 'C', '¬∫', 'Z', 'N', '5', '‚Äì', ';', 'c', 'D', 'F', 'd', 'J', 'w', '7', 'v', '√∫', 'V', 'W', '8', 'i', '&', '‚Ç¨', '9', 'K', 'l', 'x', '–∞', '-', 'L', 'h', '%', 'g', 'T', 'z', '6', '√ß', 'y', 'R', 'f']\n",
      "['B', '√π', 'q', 'U', '0', '3', 'e', '√∂', 'I', '\\u200b', 'p', 'n', '‚Äô', 'o', 'H', '√î', 'a', 'k', '‚ÇÇ', 'P', 'E', '?', 's', '1', 'G', '\"', '!', ' ', '$', '‚ÄΩ', ',', 'S', '+', 'j', 'Y', '√Ä', '\\xa0', '√®', '√á', '.', '‚Ä¶', '√©', 'r', 'M', '2', '4', 'A', '\\u2009', 'O', '√Æ', ':', 'b', '√¥', '/', 'u', 'X', 'Ô∏è', 't', '‚Äò', '√†', '√™', 'm', 'Q', \"'\", '√ª', '¬ª', 'C', '√Ø', 'Z', 'N', '5', '‚Äì', ';', 'c', 'D', 'F', 'd', '√´', 'J', 'w', '7', 'v', 'üè¥', '(', 'V', 'W', '8', 'i', '&', ')', '9', '–°', 'üè≥', '√ä', '√¢', 'K', 'l', 'x', '\\u202f', '-', 'L', 'h', 'g', '%', 'T', '¬´', '√â', 'z', '6', '√ß', 'y', 'R', 'f', '≈ì', '√°', '√Ç']\n"
     ]
    }
   ],
   "source": [
    "english_characters = set()\n",
    "french_characters = set()\n",
    "\n",
    "for str_en, str_fr in pairs_cleaned_with_marker:\n",
    "    [english_characters.add(char) for char in str_en]\n",
    "    [french_characters.add(char) for char in str_fr]\n",
    "\n",
    "english_characters = list(english_characters)\n",
    "french_characters = list(french_characters)\n",
    "\n",
    "print(english_characters)\n",
    "print(french_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um unser Modell sp√§ter mit passenden Eingabedaten f√ºttern zu k√∂nnen, m√ºssen wir nun noch die jeweiligen Vektorl√§ngen f√ºr den encoder und den decoder bestimmen. Speichert die L√§ngen in den Variablen  `encoder_vector_len` und `decoder_vector_len` ab. Hinweis: uns Modell bekommt Vektoren, die die Characters pro Wort abbilden als Eingabe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "encoder_vector_len = len(english_characters)#TODO\n",
    "decoder_vector_len = len(french_characters)#TODO\n",
    "print(encoder_vector_len)\n",
    "print(decoder_vector_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die Eingabevektoren bestimmen zu k√∂nnen, m√ºssen wir uns noch Dictionaries bauen, die jeweils die Character auf die Komponenten des Vektors abbilden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': 0, 't': 47, 'q': 1, 'U': 2, '‚Äò': 48, 'g': 83, '0': 3, '3': 4, 'e': 5, '√∂': 6, 'I': 7, 'm': 49, 'Q': 50, 'p': 8, '‚Äô': 10, 'o': 11, '–∞': 78, 'H': 12, 'C': 52, 'a': 13, '‚ÇÇ': 15, '¬∫': 53, 'Z': 54, '5': 56, 'w': 64, '‚Äì': 57, ';': 58, 'P': 16, 'z': 85, ' ': 24, 'i': 71, '?': 18, 'c': 59, 'D': 60, 'F': 61, '1': 20, 'G': 21, '!': 23, 'J': 63, 'N': 55, '7': 65, '\"': 22, 'k': 14, 'v': 66, '$': 25, ',': 26, 'S': 27, '+': 28, '√∫': 67, 'V': 68, 'j': 29, '8': 70, 'Y': 30, '&': 72, '‚Ç¨': 73, '\\xa0': 31, '9': 74, '.': 32, 'K': 75, '√©': 33, 'n': 9, 'l': 76, 'x': 77, 'r': 34, '‚Äî': 35, '-': 79, 'M': 36, \"'\": 51, 'h': 81, '2': 37, '%': 82, 'L': 80, 'T': 84, '4': 38, 'A': 39, 'd': 62, 'E': 17, 'O': 40, '6': 86, 's': 19, 'f': 90, '√ß': 87, 'W': 69, ':': 41, '\\xad': 42, 'b': 43, 'y': 88, 'R': 89, '/': 44, 'u': 45, 'X': 46}\n",
      "{'B': 0, '√π': 1, 'q': 2, 'U': 3, '‚Äò': 58, '0': 4, '√†': 59, '√™': 60, '3': 5, 'e': 6, '%': 103, '√∂': 7, '\\u200b': 9, 'm': 61, 'Q': 62, 'p': 10, \"'\": 63, 'o': 13, '√ª': 64, 'H': 14, 'k': 17, '√î': 15, '¬ª': 65, 'L': 100, 'C': 66, 'a': 16, '‚ÇÇ': 18, 'Z': 68, '5': 70, 'w': 79, '‚Äì': 71, ';': 72, 'P': 19, '√Ø': 67, 'E': 20, '?': 21, 'c': 73, 'D': 74, 'F': 75, '1': 23, 'd': 76, '√´': 77, '!': 26, 'J': 78, 'N': 69, '7': 80, ' ': 27, '.': 39, 'x': 97, 'v': 81, '$': 28, '‚ÄΩ': 29, ',': 30, 'üè¥': 82, '‚Äô': 12, '(': 83, '+': 32, 'V': 84, '–°': 91, 'j': 33, '8': 86, 'Y': 34, '&': 88, '√Ä': 35, '\\xa0': 36, ')': 89, '9': 90, 'I': 8, 'üè≥': 92, '√ä': 93, '√®': 37, '√¢': 94, '√á': 38, 'K': 95, 'i': 87, 'S': 31, '√©': 41, 'l': 96, 's': 22, 'r': 42, '\\u202f': 98, '-': 99, 'M': 43, 'n': 11, '¬´': 105, 'h': 101, '2': 44, 'g': 102, '\"': 25, 'T': 104, '4': 45, 'A': 46, 'G': 24, '√â': 106, 'z': 107, 'O': 48, '6': 108, 'f': 112, '√ß': 109, '\\u2009': 47, '‚Ä¶': 40, '√Æ': 49, 'W': 85, ':': 50, 'b': 51, 't': 57, '√Ç': 115, 'y': 110, 'R': 111, '√¥': 52, '/': 53, '≈ì': 113, '√°': 114, 'u': 54, 'X': 55, 'Ô∏è': 56}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "english_token_index = {char:key for key, char in enumerate(english_characters)}\n",
    "french_token_index = {char:key for key, char in enumerate(french_characters)}\n",
    "\n",
    "print(english_token_index) #token2idx\n",
    "print(french_token_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben nun alle Dimensionen bestimmt, um die Trainingsdaten zu definieren. Daf√ºr bauen wir uns drei Matrizen (eine als Eingabe f√ºr den Encoder, eine als Eingabe f√ºr den Decoder und eine als Ausgabe des Decoders) zusammen. Die Dimensionen daf√ºr sind jeweils: Anzahl S√§tze, Anzahl W√∂rter des l√§ngsten Satzes, Anzahl Characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_encoder_sentence_len = max((len(e) for e, _ in pairs_cleaned_with_marker))\n",
    "max_decoder_sentence_len = max((len(f) for _, f in pairs_cleaned_with_marker))\n",
    "\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(pairs_cleaned_with_marker), max_encoder_sentence_len, encoder_vector_len),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(pairs_cleaned_with_marker), max_decoder_sentence_len, decoder_vector_len),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(pairs_cleaned_with_marker), max_decoder_sentence_len, decoder_vector_len),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bef√ºllt nun die Matrizen. Die `encoder_input_data` und die `decoder_input_data`-Matrix soll f√ºr jeden Satz aus den Trainingsdaten, einen Eintrag mit einem Token-Vektor pro Wort enthalten.\n",
    "Die `decoder_target_data`-Matrix soll den gleichen Inhalt wie die `decoder_input_data`-Matrix haben, allerdings um eine Position verschoben. (Schaut euch nochmal die Folien an, wir brauchen Platz f√ºr das Startsymbol) \n",
    "\n",
    "Die `encoder_input_data`-Matrix wird mit den englischen Daten bef√ºllt, die beiden anderen mit den franz√∂sischen Daten.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (e, f) in enumerate(pairs_cleaned_with_marker):\n",
    "    for t, char in enumerate(e):\n",
    "        encoder_input_data[i, t, english_token_index[char]] = 1.\n",
    "    for t, char in enumerate(f):\n",
    "        decoder_input_data[i, t, french_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t-1, french_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence Modelle\n",
    "\n",
    "Im Gegensatz zu den bisherigen Notebooks, wollen wir hier mit dem Modell beginnen. Einerseits, weil die Daten eher dr√∂ge  (trocken) sind (englisch-fr√§nzosische Satzpaare), andererseits, weil das Modell selbst komplizierter ist und wir hier die Functional-API von Keras benutzen m√ºssen.\n",
    "\n",
    "Im Gegensatz zu der Sequence-API, definiert man hier ein Modell in dem, den jeweiligen Layer mit dem Vorg√§nger Layer aufruft:\n",
    "```\n",
    "\n",
    "a = Input(...)\n",
    "b = Dense(...)\n",
    "\n",
    "t = b(a)\n",
    "\n",
    "\n",
    "```\n",
    "Als R√ºckgabe bekommt man einen Tensor.\n",
    "\n",
    "\n",
    "Ganz generell gesprochen, m√∂chten wir hier ein Seq2Seq-Modell aufbauen, das auf LSTMs basiert. Wie auf den Folien beschrieben wurde, teilt sich so ein Modell in einen Encoder und Decoder auf. \n",
    "Wir beginnen die Implementierung mit dem Encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "\n",
    "Auch das komplexeste Modell f√§ngt mit einer Eingabe ein.\n",
    "\n",
    "Definiert einen Input-Layer, der als Eingabedimension, S√§tze beliebiger L√§nge als Vektoren nimmt. Eine Komponente im Vektor repr√§sentiert einen Character. Unbekannte Teile der Eingabedimensionen kann man mit `None` definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "encoder_input = Input(shape=(None, encoder_vector_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als n√§chstes definiert einen LSTM-Layer, der 256 hidden units hat. Die Ausgabe des Layers soll sp√§ter an den Decoder 'verf√ºttert' werden. Seht in der Dokumentation nach wie man den Thought-Vektor zur√ºckbekommen kann (https://keras.io/layers/recurrent/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "lstm_hu = 256\n",
    "encoder = LSTM(units=lstm_hu, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbindet nun den `encoder_input`-Layer mit dem `encoder`-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "_, state_h, state_c = encoder(encoder_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Encoder w√§re damit fertig implementiert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder\n",
    "\n",
    "Auch der Decoder f√§ngt mit einem Input-Layer an. Definiert einen Input-Layer analog zum Encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None, decoder_vector_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie auch im Encoder, ist das Herzst√ºck ein LSTM-Layer. Definiert einen LSTM-Layer mit 256 hidden units. Seht in der Dokumentation nach, wie man neben den Thought-Vektoren, auch die komplette Ausgabe-Sequence zur√ºckbekommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(256, return_state=True, return_sequences=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbindet nun den `decoder_input`-Layer mit dem `decoder_lstm`-Layer. An welcher der drei Ausgaben sind wir hier interessiert? Au√üerdem m√ºssen wir hier, den Thought-Vektor des Encoders mit √ºbergeben, dies geschieht √ºber den `initial_state`-Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences ,_,_ = decoder_lstm(decoder_input, initial_state=[state_h,state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Abschluss unseres Modells bildet ein Dense-Layer, der gleich viele `hidden_units` wie der Input-Layer des Decoders hat. Als Aktivierungsfunktion nehmen wir die Softmax-Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "decoder_layer = Dense(decoder_vector_len, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verbindet diesen Layer mit den bisherigen Decoder sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = decoder_layer(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben nun alle Elemente f√ºr ein Sequence-To-Sequence-Modell zusammen. Im letzten Schritt bauen wir das ganze Modell zusammen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True\n",
    "if not TRAIN:\n",
    "    import keras\n",
    "    from keras.models import load_model\n",
    "    from keras.utils import CustomObjectScope\n",
    "    from keras.initializers import glorot_uniform\n",
    "\n",
    "    with CustomObjectScope({'GlorotUniform': glorot_uniform()}):\n",
    "        model = load_model('model15.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativ statt laden trainieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "if TRAIN:\n",
    "    model = Model(inputs=[encoder_input, decoder_input], outputs=[decoder])\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fertig! Nun kann das Modell trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 133704 samples, validate on 33426 samples\n",
      "Epoch 1/150\n",
      "133704/133704 [==============================] - 412s 3ms/step - loss: 0.2106 - val_loss: 0.3250\n",
      "Epoch 2/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.1486 - val_loss: 0.2728\n",
      "Epoch 3/150\n",
      "133704/133704 [==============================] - 378s 3ms/step - loss: 0.1249 - val_loss: 0.2458\n",
      "Epoch 4/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.1118 - val_loss: 0.2279\n",
      "Epoch 5/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.1039 - val_loss: 0.2193\n",
      "Epoch 6/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.0983 - val_loss: 0.2081\n",
      "Epoch 7/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0949 - val_loss: 0.2035\n",
      "Epoch 8/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0918 - val_loss: 0.2016\n",
      "Epoch 9/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0894 - val_loss: 0.1948\n",
      "Epoch 10/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.0863 - val_loss: 0.1878\n",
      "Epoch 11/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0843 - val_loss: 0.1847\n",
      "Epoch 12/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.0822 - val_loss: 0.1813\n",
      "Epoch 13/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0799 - val_loss: 0.1796\n",
      "Epoch 14/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.0782 - val_loss: 0.1770\n",
      "Epoch 15/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0770 - val_loss: 0.1758\n",
      "Epoch 16/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0757 - val_loss: 0.1762\n",
      "Epoch 17/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0745 - val_loss: 0.1745\n",
      "Epoch 18/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.0732 - val_loss: 0.1753\n",
      "Epoch 19/150\n",
      "133704/133704 [==============================] - 382s 3ms/step - loss: 0.0730 - val_loss: 0.1758\n",
      "Epoch 20/150\n",
      "133704/133704 [==============================] - 389s 3ms/step - loss: 0.0721 - val_loss: 0.1718\n",
      "Epoch 21/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0710 - val_loss: 0.1694\n",
      "Epoch 22/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0701 - val_loss: 0.1697\n",
      "Epoch 23/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0693 - val_loss: 0.1692\n",
      "Epoch 24/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0686 - val_loss: 0.1681\n",
      "Epoch 25/150\n",
      "133704/133704 [==============================] - 379s 3ms/step - loss: 0.0679 - val_loss: 0.1702\n",
      "Epoch 26/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0674 - val_loss: 0.1690\n",
      "Epoch 27/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0669 - val_loss: 0.1661\n",
      "Epoch 28/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0663 - val_loss: 0.1698\n",
      "Epoch 29/150\n",
      "133704/133704 [==============================] - 386s 3ms/step - loss: 0.0658 - val_loss: 0.1675\n",
      "Epoch 30/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0652 - val_loss: 0.1672\n",
      "Epoch 31/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0647 - val_loss: 0.1679\n",
      "Epoch 32/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0643 - val_loss: 0.1670\n",
      "Epoch 33/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0639 - val_loss: 0.1677\n",
      "Epoch 34/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0635 - val_loss: 0.1665\n",
      "Epoch 35/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0632 - val_loss: 0.1666\n",
      "Epoch 36/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0628 - val_loss: 0.1675\n",
      "Epoch 37/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0624 - val_loss: 0.1652\n",
      "Epoch 38/150\n",
      "133704/133704 [==============================] - 386s 3ms/step - loss: 0.0621 - val_loss: 0.1685\n",
      "Epoch 39/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0620 - val_loss: 0.1684\n",
      "Epoch 40/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0615 - val_loss: 0.1672\n",
      "Epoch 41/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0612 - val_loss: 0.1660\n",
      "Epoch 42/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0609 - val_loss: 0.1665\n",
      "Epoch 43/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0607 - val_loss: 0.1673\n",
      "Epoch 44/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0611 - val_loss: 0.1660\n",
      "Epoch 45/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0602 - val_loss: 0.1662\n",
      "Epoch 46/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0599 - val_loss: 0.1680\n",
      "Epoch 47/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0596 - val_loss: 0.1669\n",
      "Epoch 48/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0594 - val_loss: 0.1672\n",
      "Epoch 49/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0592 - val_loss: 0.1686\n",
      "Epoch 50/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0590 - val_loss: 0.1716\n",
      "Epoch 51/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0588 - val_loss: 0.1677\n",
      "Epoch 52/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0586 - val_loss: 0.1680\n",
      "Epoch 53/150\n",
      "133704/133704 [==============================] - 386s 3ms/step - loss: 0.0584 - val_loss: 0.1676\n",
      "Epoch 54/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0582 - val_loss: 0.1702\n",
      "Epoch 55/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0580 - val_loss: 0.1681\n",
      "Epoch 56/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0577 - val_loss: 0.1678\n",
      "Epoch 57/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0575 - val_loss: 0.1687\n",
      "Epoch 58/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0576 - val_loss: 0.1676\n",
      "Epoch 59/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0573 - val_loss: 0.1701\n",
      "Epoch 60/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0571 - val_loss: 0.1709\n",
      "Epoch 61/150\n",
      "133704/133704 [==============================] - 386s 3ms/step - loss: 0.0569 - val_loss: 0.1711\n",
      "Epoch 62/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0567 - val_loss: 0.1695\n",
      "Epoch 63/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0566 - val_loss: 0.1695\n",
      "Epoch 64/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0565 - val_loss: 0.1719\n",
      "Epoch 65/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0563 - val_loss: 0.1695\n",
      "Epoch 66/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0561 - val_loss: 0.1701\n",
      "Epoch 67/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0560 - val_loss: 0.1725\n",
      "Epoch 68/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0558 - val_loss: 0.1722\n",
      "Epoch 69/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0559 - val_loss: 0.1698\n",
      "Epoch 70/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0558 - val_loss: 0.1700\n",
      "Epoch 71/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0555 - val_loss: 0.1712\n",
      "Epoch 72/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0553 - val_loss: 0.1710\n",
      "Epoch 73/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0552 - val_loss: 0.1715\n",
      "Epoch 74/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0550 - val_loss: 0.1711\n",
      "Epoch 75/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0549 - val_loss: 0.1725\n",
      "Epoch 76/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0548 - val_loss: 0.1734\n",
      "Epoch 77/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0547 - val_loss: 0.1735\n",
      "Epoch 78/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0546 - val_loss: 0.1718\n",
      "Epoch 79/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0547 - val_loss: 0.1717\n",
      "Epoch 80/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0544 - val_loss: 0.1715\n",
      "Epoch 81/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0543 - val_loss: 0.1722\n",
      "Epoch 82/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0541 - val_loss: 0.1723\n",
      "Epoch 83/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0540 - val_loss: 0.1738\n",
      "Epoch 84/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0539 - val_loss: 0.1733\n",
      "Epoch 85/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0538 - val_loss: 0.1724\n",
      "Epoch 86/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0538 - val_loss: 0.1739\n",
      "Epoch 87/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0536 - val_loss: 0.1737\n",
      "Epoch 88/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0535 - val_loss: 0.1759\n",
      "Epoch 89/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0534 - val_loss: 0.1742\n",
      "Epoch 90/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0534 - val_loss: 0.1741\n",
      "Epoch 91/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0533 - val_loss: 0.1737\n",
      "Epoch 92/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0532 - val_loss: 0.1748\n",
      "Epoch 93/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0531 - val_loss: 0.1742\n",
      "Epoch 94/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0531 - val_loss: 0.1755\n",
      "Epoch 95/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0530 - val_loss: 0.1764\n",
      "Epoch 96/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0529 - val_loss: 0.1762\n",
      "Epoch 97/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0527 - val_loss: 0.1743\n",
      "Epoch 98/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0527 - val_loss: 0.1750\n",
      "Epoch 99/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0526 - val_loss: 0.1759\n",
      "Epoch 100/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0525 - val_loss: 0.1782\n",
      "Epoch 101/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0524 - val_loss: 0.1764\n",
      "Epoch 102/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0524 - val_loss: 0.1779\n",
      "Epoch 103/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0523 - val_loss: 0.1771\n",
      "Epoch 104/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0523 - val_loss: 0.1790\n",
      "Epoch 105/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0525 - val_loss: 0.1776\n",
      "Epoch 106/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0523 - val_loss: 0.1772\n",
      "Epoch 107/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0521 - val_loss: 0.1765\n",
      "Epoch 108/150\n",
      "133704/133704 [==============================] - 390s 3ms/step - loss: 0.0520 - val_loss: 0.1765\n",
      "Epoch 109/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0520 - val_loss: 0.1786\n",
      "Epoch 110/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0560 - val_loss: 0.1785\n",
      "Epoch 111/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0564 - val_loss: 0.1784\n",
      "Epoch 112/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0565 - val_loss: 0.1775\n",
      "Epoch 113/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0540 - val_loss: 0.1756\n",
      "Epoch 114/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0525 - val_loss: 0.1755\n",
      "Epoch 115/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0521 - val_loss: 0.1779\n",
      "Epoch 116/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0519 - val_loss: 0.1751\n",
      "Epoch 117/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0518 - val_loss: 0.1775\n",
      "Epoch 118/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0518 - val_loss: 0.1825\n",
      "Epoch 119/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0555 - val_loss: 0.1789\n",
      "Epoch 120/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0561 - val_loss: 0.1772\n",
      "Epoch 121/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0535 - val_loss: 0.1766\n",
      "Epoch 122/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0525 - val_loss: 0.1763\n",
      "Epoch 123/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0518 - val_loss: 0.1788\n",
      "Epoch 124/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0516 - val_loss: 0.1755\n",
      "Epoch 125/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0514 - val_loss: 0.1774\n",
      "Epoch 126/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0514 - val_loss: 0.1784\n",
      "Epoch 127/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0513 - val_loss: 0.1779\n",
      "Epoch 128/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0511 - val_loss: 0.1809\n",
      "Epoch 129/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0510 - val_loss: 0.1783\n",
      "Epoch 130/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0510 - val_loss: 0.1793\n",
      "Epoch 131/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0509 - val_loss: 0.1789\n",
      "Epoch 132/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0508 - val_loss: 0.1784\n",
      "Epoch 133/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0508 - val_loss: 0.1786\n",
      "Epoch 134/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0507 - val_loss: 0.1809\n",
      "Epoch 135/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0513 - val_loss: 0.1788\n",
      "Epoch 136/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0511 - val_loss: 0.1787\n",
      "Epoch 137/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0508 - val_loss: 0.1808\n",
      "Epoch 138/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0508 - val_loss: 0.1795\n",
      "Epoch 139/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0506 - val_loss: 0.1831\n",
      "Epoch 140/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0505 - val_loss: 0.1791\n",
      "Epoch 141/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0505 - val_loss: 0.1818\n",
      "Epoch 142/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0504 - val_loss: 0.1802\n",
      "Epoch 143/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0515 - val_loss: 0.1797\n",
      "Epoch 144/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0516 - val_loss: 0.1802\n",
      "Epoch 145/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0505 - val_loss: 0.1815\n",
      "Epoch 146/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0503 - val_loss: 0.1799\n",
      "Epoch 147/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0502 - val_loss: 0.1826\n",
      "Epoch 148/150\n",
      "133704/133704 [==============================] - 391s 3ms/step - loss: 0.0502 - val_loss: 0.1810\n",
      "Epoch 149/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0501 - val_loss: 0.1814\n",
      "Epoch 150/150\n",
      "133704/133704 [==============================] - 392s 3ms/step - loss: 0.0500 - val_loss: 0.1828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/network.py:877: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "              batch_size=256,\n",
    "              epochs=150,\n",
    "              validation_split=0.2)\n",
    "\n",
    "    model.save('model150.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inferenz\n",
    "\n",
    "Um mit dem trainierten Modell Texte √ºbersetzen zu k√∂nnen, m√ºssen wir nun noch unser bisheriges Modell etwas umbauen.\n",
    "Im ersten Schritt definieren wir uns ein `Model` das einen Eingabetext encodiert. Als Eingabe hat dieses `Model` den bisherigen `encoder_input`-Layer und die Thought-Vektoren als Output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_input, [state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 91)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                [(None, 256), (None, 256) 356352    \n",
      "=================================================================\n",
      "Total params: 356,352\n",
      "Trainable params: 356,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etwas komplizierter ist das Decoder-Modell. Als Input nimmt es zum einen die Thought-Vektoren des Encoders, zum anderen den `decoder_input`-Layer von oben.\n",
    "Definiert zun√§chst zwei Input-Layer f√ºr die Thought-Vektoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(lstm_hu,))\n",
    "decoder_state_input_c = Input(shape=(lstm_hu,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setzt diese beiden Input-Layer als `initial_state` und den `decoder_input`-Layer als Input in das `decoder_lstm` von oben ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_sequences, state_h, state_c = decoder_lstm(decoder_input, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setzt nun den `decoder_outputs`-Tensor in den `decoder_layer` von oben ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_layer(decoder_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun k√∂nnen wir ein `Model` zusammenbauen, das uns als Decoder dient. Input ist hier der `decoder_input`-Layer, zusammen mit den `decoder_state_input_h` und dem `decoder_state_input_c`-Tensor. Als Output dient uns der `decoder_outputs`-Tensor und der `state_h` mit dem `state_c`-Tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(inputs=[decoder_input, decoder_state_input_h, decoder_state_input_c], outputs=[decoder_outputs, state_h, state_c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein kleiner Zwischenschritt ist noch n√∂tig, bevor wir mit dem Modell Texte √ºbersetzen k√∂nnen. Damit wir aus unseren Vektoren wieder Texte bekommen, m√ºssen wir noch das Dictionary `reverse_french_token_index` bef√ºllen, das die \"Umkehrung\" von `french_token_index` ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_french_token_index = {idx:token for token, idx in french_token_index.items()} #idx2token\n",
    "reverse_english_token_index = {idx:token for token, idx in english_token_index.items()} #idx2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'B', 1: '√π', 2: 'q', 3: 'U', 4: '0', 5: '3', 6: 'e', 7: '√∂', 8: 'I', 9: '\\u200b', 10: 'p', 11: 'n', 12: '‚Äô', 13: 'o', 14: 'H', 15: '√î', 16: 'a', 17: 'k', 18: '‚ÇÇ', 19: 'P', 20: 'E', 21: '?', 22: 's', 23: '1', 24: 'G', 25: '\"', 26: '!', 27: ' ', 28: '$', 29: '‚ÄΩ', 30: ',', 31: 'S', 32: '+', 33: 'j', 34: 'Y', 35: '√Ä', 36: '\\xa0', 37: '√®', 38: '√á', 39: '.', 40: '‚Ä¶', 41: '√©', 42: 'r', 43: 'M', 44: '2', 45: '4', 46: 'A', 47: '\\u2009', 48: 'O', 49: '√Æ', 50: ':', 51: 'b', 52: '√¥', 53: '/', 54: 'u', 55: 'X', 56: 'Ô∏è', 57: 't', 58: '‚Äò', 59: '√†', 60: '√™', 61: 'm', 62: 'Q', 63: \"'\", 64: '√ª', 65: '¬ª', 66: 'C', 67: '√Ø', 68: 'Z', 69: 'N', 70: '5', 71: '‚Äì', 72: ';', 73: 'c', 74: 'D', 75: 'F', 76: 'd', 77: '√´', 78: 'J', 79: 'w', 80: '7', 81: 'v', 82: 'üè¥', 83: '(', 84: 'V', 85: 'W', 86: '8', 87: 'i', 88: '&', 89: ')', 90: '9', 91: '–°', 92: 'üè≥', 93: '√ä', 94: '√¢', 95: 'K', 96: 'l', 97: 'x', 98: '\\u202f', 99: '-', 100: 'L', 101: 'h', 102: 'g', 103: '%', 104: 'T', 105: '¬´', 106: '√â', 107: 'z', 108: '6', 109: '√ß', 110: 'y', 111: 'R', 112: 'f', 113: '≈ì', 114: '√°', 115: '√Ç'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_french_token_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun k√∂nnen wir eine Funktion `translate` implementieren, die als Eingabe einen englischen Text als Vektoren nimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#first start: predict_char(french_token_index[\"üè≥\"], thought[0], thought[1]) -> french_char_idx, h, c\n",
    "#every iter: predict_char(french_char_idx, h, c) -> french_char_idx, h, c\n",
    "\n",
    "\n",
    "def predict_char(prev_char_idx, state_h, state_c):\n",
    "    french_char_onehot = np.zeros((1, 1, decoder_vector_len))\n",
    "    french_char_onehot[0, 0, prev_char_idx] = 1\n",
    "    predicted_chars_probs, h, c = decoder_model.predict([french_char_onehot, state_h, state_c])\n",
    "    predicted_french_char_idx = np.argmax(predicted_chars_probs)\n",
    "    predicted_french_char = reverse_french_token_index[predicted_french_char_idx]\n",
    "    return predicted_french_char_idx, predicted_french_char, h, c\n",
    "\n",
    "def translate(english_text):\n",
    "    # Wandelt mit dem encoder_model, `english_text` in einen Thought-Vektor um\n",
    "    thought = encoder_model.predict(english_text)\n",
    "    \n",
    "    translation = \"\"\n",
    "    \n",
    "    predicted_french_char_idx, h, c = french_token_index[\"üè≥\"], thought[0], thought[1]\n",
    "    \n",
    "    while predicted_french_char_idx != french_token_index[\"üè¥\"]:\n",
    "        predicted_french_char_idx, predicted_french_char, h, c = predict_char(predicted_french_char_idx, h, c)\n",
    "        #print(h[0][0])\n",
    "        translation += predicted_french_char\n",
    "    \n",
    "    return translation[:-1]\n",
    "\n",
    "    \"\"\"\n",
    "    ----------\n",
    "    # Als Input f√ºr den Decoder, wird zum einen der thought-Vektor ben√∂tigt, \n",
    "    # zum anderen die Vektor-Repr√§sentation des Startsymbols\n",
    "    french_text = np.zeros((1, 1, decoder_vector_len)) #TODO\n",
    "    \n",
    "    # Belegt die Komponente des Start-Symbols mit 1\n",
    "    french_text[0, 0, french_token_index[\"üè≥\"]] = 1.  #TODO\n",
    "    \n",
    "    # und √ºbergebt beides an den Decoder\n",
    "    chars, h, c = decoder_model.predict([french_text] + thought)\n",
    "    print(chars)\n",
    "    # chars beinhaltet eine 1 x 1 x decoder_vector_len Matrix, die f√ºr jeden franz√∂sische Character\n",
    "    # eine Art \"Wahrscheinlichkeit\" angibt.\n",
    "    # Findet die Komponente, mit der gr√∂√üten Wahrscheinlichkeit und wandelt sie in ein Character um\n",
    "    french_char_idx = np.argmax(chars) #TODO\n",
    "    french_char = reverse_french_token_index[french_char_idx]\n",
    "    print(french_char_idx, french_char)\n",
    "    \n",
    "    -------------------\n",
    "    # die n√§chste Prediction w√§re dann\n",
    "    french_text = np.zeros((1, 1, decoder_vector_len))\n",
    "    french_text[0, 0, french_char_idx] = 1.\n",
    "    chars, h, c = decoder_model.predict([french_text, h, c])\n",
    "    french_char_idx = np.argmax(chars) #TODO\n",
    "    french_char = reverse_french_token_index[french_char_idx]\n",
    "    print(french_char_idx, french_char)\n",
    "    -----------------\n",
    "    \"\"\"\n",
    "    # TODO: baut eine Schleife mit geeigneter Abbruchbedingung, die die Schritte von oben umfasst \n",
    "    # und dabei aus french_char einen √ºbersetzen Text zusammenbaut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 286, 91) 286 91\n",
      "-- English --\n",
      "Stop!BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB\n",
      "-- French --\n",
      "Ô∏èArr√™tez !\n"
     ]
    }
   ],
   "source": [
    "english_text = np.array([encoder_input_data[10]])\n",
    "print(english_text.shape, len(english_text[0]), encoder_vector_len)\n",
    "\n",
    "french_text = translate(english_text)\n",
    "\n",
    "print(\"-- English --\")\n",
    "#print(pairs_cleaned_with_marker[10])\n",
    "print(\"\".join([reverse_english_token_index[np.argmax(char)] for char in english_text[0]]))\n",
    "print(\"-- French --\")\n",
    "print(french_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Go.', 'üè≥Ô∏èVa !üè¥'), ('Hi.', 'üè≥Ô∏èSalut !üè¥'), ('Run!', 'üè≥Ô∏èCours\\u202f!üè¥')]\n"
     ]
    }
   ],
   "source": [
    "print(pairs_cleaned_with_marker[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_string = \"\"\n",
    "\n",
    "for text in encoder_input_data:\n",
    "    english_text = np.array([text])\n",
    "    english_text_string = \"\".join([reverse_english_token_index[np.argmax(char)] for char in english_text[0]])\n",
    "    french_text = translate(english_text)\n",
    "    output_string += english_text_string + \"|||||\" + french_text + \"\\n-----------------------\\n\"\n",
    "    \n",
    "with open(\"translation.txt\", \"w\") as f:\n",
    "    f.write(output_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
